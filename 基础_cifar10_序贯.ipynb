{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "基础_cifar10_序贯.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/jsxyhelu/DateSets/blob/master/%E5%9F%BA%E7%A1%80_cifar10_%E5%BA%8F%E8%B4%AF.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "61c_YbOqZz-V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "发现这段官方的代码，给出的就是带argumentation的结果"
      ]
    },
    {
      "metadata": {
        "id": "tY-OlUCpYTUj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2837
        },
        "outputId": "750de511-8d15-4423-9d57-23bc4ca6708b"
      },
      "cell_type": "code",
      "source": [
        "'''Train a simple deep CNN on the CIFAR10 small images dataset.\n",
        "\n",
        "It gets to 75% validation accuracy in 25 epochs, and 79% after 50 epochs.\n",
        "(it's still underfitting at that point, though).\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "!apt-get -qq install -y graphviz && pip install -q pydot\n",
        "import pydot\n",
        "import keras\n",
        "import cv2\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.image as image # image 用于读取图片\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "#epochs = 3\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Conv2D(32, (3, 3)))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(512))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(num_classes))\n",
        "model2.add(Activation('softmax'))\n",
        "\n",
        "#显示模型\n",
        "model.summary()\n",
        "plot_model(model,to_file='model1111.png',show_shapes=True)\n",
        "img = image.imread('model1111.png')\n",
        "print(img.shape)\n",
        "plt.imshow(img) # 显示图片\n",
        "plt.axis('off') # 不显示坐标轴\n",
        "plt.show()\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    #使用了数据自动增长\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "    \n",
        "    model2.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n",
        "\n",
        "scores = model2.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss2:', scores[0])\n",
        "print('Test accuracy2:', scores[1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(2065, 635, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAN0AAAH4CAYAAADO0ugrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa44253da20>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 110,
              "height": 252
            }
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
            "Epoch 1/20\n",
            " 677/1563 [===========>..................] - ETA: 28s - loss: 2.0170 - acc: 0.2465"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 49s 32ms/step - loss: 1.8591 - acc: 0.3119 - val_loss: 1.5783 - val_acc: 0.4260\n",
            "Epoch 2/20\n",
            " 618/1563 [==========>...................] - ETA: 27s - loss: 1.6249 - acc: 0.3997"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 48s 31ms/step - loss: 1.5880 - acc: 0.4165 - val_loss: 1.3933 - val_acc: 0.4920\n",
            "Epoch 3/20\n",
            " 588/1563 [==========>...................] - ETA: 28s - loss: 1.4932 - acc: 0.4551"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 48s 30ms/step - loss: 1.4702 - acc: 0.4662 - val_loss: 1.3209 - val_acc: 0.5227\n",
            "Epoch 4/20\n",
            " 589/1563 [==========>...................] - ETA: 28s - loss: 1.4244 - acc: 0.4877"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 48s 30ms/step - loss: 1.3970 - acc: 0.4987 - val_loss: 1.2169 - val_acc: 0.5642\n",
            "Epoch 5/20\n",
            " 587/1563 [==========>...................] - ETA: 28s - loss: 1.3525 - acc: 0.5144"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 48s 31ms/step - loss: 1.3308 - acc: 0.5239 - val_loss: 1.2906 - val_acc: 0.5430\n",
            "Epoch 6/20\n",
            " 575/1563 [==========>...................] - ETA: 28s - loss: 1.2907 - acc: 0.5421"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.2737 - acc: 0.5474 - val_loss: 1.1951 - val_acc: 0.5746\n",
            "Epoch 7/20\n",
            " 575/1563 [==========>...................] - ETA: 28s - loss: 1.2457 - acc: 0.5590"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.2225 - acc: 0.5647 - val_loss: 1.1014 - val_acc: 0.6100\n",
            "Epoch 8/20\n",
            " 561/1563 [=========>....................] - ETA: 29s - loss: 1.1863 - acc: 0.5789"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 48s 31ms/step - loss: 1.1747 - acc: 0.5842 - val_loss: 1.0937 - val_acc: 0.6221\n",
            "Epoch 9/20\n",
            " 541/1563 [=========>....................] - ETA: 29s - loss: 1.1461 - acc: 0.5978"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 48s 30ms/step - loss: 1.1385 - acc: 0.5989 - val_loss: 0.9735 - val_acc: 0.6573\n",
            "Epoch 10/20\n",
            " 546/1563 [=========>....................] - ETA: 29s - loss: 1.1050 - acc: 0.6069"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 48s 31ms/step - loss: 1.0972 - acc: 0.6105 - val_loss: 0.9898 - val_acc: 0.6531\n",
            "Epoch 11/20\n",
            " 546/1563 [=========>....................] - ETA: 29s - loss: 1.0874 - acc: 0.6154"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 48s 31ms/step - loss: 1.0659 - acc: 0.6238 - val_loss: 0.9277 - val_acc: 0.6779\n",
            "Epoch 12/20\n",
            " 571/1563 [=========>....................] - ETA: 28s - loss: 1.0403 - acc: 0.6364"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.0328 - acc: 0.6374 - val_loss: 0.9603 - val_acc: 0.6635\n",
            "Epoch 13/20\n",
            " 582/1563 [==========>...................] - ETA: 28s - loss: 1.0142 - acc: 0.6440"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.0065 - acc: 0.6475 - val_loss: 0.9076 - val_acc: 0.6865\n",
            "Epoch 14/20\n",
            " 570/1563 [=========>....................] - ETA: 28s - loss: 0.9989 - acc: 0.6495"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.9886 - acc: 0.6518 - val_loss: 0.8825 - val_acc: 0.6907\n",
            "Epoch 15/20\n",
            " 564/1563 [=========>....................] - ETA: 28s - loss: 0.9725 - acc: 0.6620"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.9696 - acc: 0.6620 - val_loss: 0.8492 - val_acc: 0.7021\n",
            "Epoch 16/20\n",
            " 577/1563 [==========>...................] - ETA: 28s - loss: 0.9509 - acc: 0.6681"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.9497 - acc: 0.6681 - val_loss: 0.8404 - val_acc: 0.7059\n",
            "Epoch 17/20\n",
            " 582/1563 [==========>...................] - ETA: 28s - loss: 0.9448 - acc: 0.6684"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 48s 31ms/step - loss: 0.9377 - acc: 0.6732 - val_loss: 0.8193 - val_acc: 0.7157\n",
            "Epoch 18/20\n",
            " 561/1563 [=========>....................] - ETA: 29s - loss: 0.9322 - acc: 0.6825"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 48s 31ms/step - loss: 0.9293 - acc: 0.6760 - val_loss: 0.8297 - val_acc: 0.7107\n",
            "Epoch 19/20\n",
            " 563/1563 [=========>....................] - ETA: 29s - loss: 0.9261 - acc: 0.6726"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 47s 30ms/step - loss: 0.9141 - acc: 0.6803 - val_loss: 0.7868 - val_acc: 0.7225\n",
            "Epoch 20/20\n",
            " 551/1563 [=========>....................] - ETA: 29s - loss: 0.9037 - acc: 0.6839"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 48s 31ms/step - loss: 0.8989 - acc: 0.6858 - val_loss: 0.8056 - val_acc: 0.7182\n",
            "Epoch 1/20\n",
            " 601/1563 [==========>...................] - ETA: 27s - loss: 1.9320 - acc: 0.3006"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 46s 30ms/step - loss: 1.7649 - acc: 0.3643 - val_loss: 1.4989 - val_acc: 0.4700\n",
            "Epoch 2/20\n",
            " 632/1563 [===========>..................] - ETA: 26s - loss: 1.5337 - acc: 0.4449"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 46s 29ms/step - loss: 1.4957 - acc: 0.4618 - val_loss: 1.3010 - val_acc: 0.5385\n",
            "Epoch 3/20\n",
            " 644/1563 [===========>..................] - ETA: 26s - loss: 1.4090 - acc: 0.4956"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 46s 30ms/step - loss: 1.3996 - acc: 0.4994 - val_loss: 1.2777 - val_acc: 0.5491\n",
            "Epoch 4/20\n",
            " 664/1563 [===========>..................] - ETA: 25s - loss: 1.3467 - acc: 0.5188"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 46s 29ms/step - loss: 1.3301 - acc: 0.5272 - val_loss: 1.1777 - val_acc: 0.5796\n",
            "Epoch 5/20\n",
            " 665/1563 [===========>..................] - ETA: 25s - loss: 1.2859 - acc: 0.5452"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 46s 29ms/step - loss: 1.2749 - acc: 0.5471 - val_loss: 1.1644 - val_acc: 0.5938\n",
            "Epoch 6/20\n",
            " 644/1563 [===========>..................] - ETA: 26s - loss: 1.2507 - acc: 0.5584"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 46s 30ms/step - loss: 1.2309 - acc: 0.5645 - val_loss: 1.0703 - val_acc: 0.6215\n",
            "Epoch 7/20\n",
            " 669/1563 [===========>..................] - ETA: 25s - loss: 1.1986 - acc: 0.5752"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 46s 29ms/step - loss: 1.1914 - acc: 0.5798 - val_loss: 1.0445 - val_acc: 0.6329\n",
            "Epoch 8/20\n",
            " 655/1563 [===========>..................] - ETA: 25s - loss: 1.1819 - acc: 0.5835"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 46s 30ms/step - loss: 1.1657 - acc: 0.5898 - val_loss: 1.0435 - val_acc: 0.6323\n",
            "Epoch 9/20\n",
            " 659/1563 [===========>..................] - ETA: 25s - loss: 1.1396 - acc: 0.5991"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 46s 30ms/step - loss: 1.1377 - acc: 0.6001 - val_loss: 1.0198 - val_acc: 0.6439\n",
            "Epoch 10/20\n",
            " 656/1563 [===========>..................] - ETA: 25s - loss: 1.1185 - acc: 0.6046"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 46s 29ms/step - loss: 1.1169 - acc: 0.6068 - val_loss: 0.9838 - val_acc: 0.6573\n",
            "Epoch 11/20\n",
            " 660/1563 [===========>..................] - ETA: 25s - loss: 1.1065 - acc: 0.6111"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 46s 29ms/step - loss: 1.1019 - acc: 0.6116 - val_loss: 1.0016 - val_acc: 0.6524\n",
            "Epoch 12/20\n",
            " 658/1563 [===========>..................] - ETA: 25s - loss: 1.0837 - acc: 0.6171"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 46s 29ms/step - loss: 1.0834 - acc: 0.6207 - val_loss: 0.9817 - val_acc: 0.6568\n",
            "Epoch 13/20\n",
            " 650/1563 [===========>..................] - ETA: 26s - loss: 1.0719 - acc: 0.6249"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 46s 30ms/step - loss: 1.0747 - acc: 0.6227 - val_loss: 0.9346 - val_acc: 0.6773\n",
            "Epoch 14/20\n",
            " 654/1563 [===========>..................] - ETA: 26s - loss: 1.0620 - acc: 0.6275"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 46s 30ms/step - loss: 1.0579 - acc: 0.6290 - val_loss: 0.9292 - val_acc: 0.6794\n",
            "Epoch 15/20\n",
            " 668/1563 [===========>..................] - ETA: 25s - loss: 1.0484 - acc: 0.6312"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 46s 30ms/step - loss: 1.0515 - acc: 0.6312 - val_loss: 0.9224 - val_acc: 0.6819\n",
            "Epoch 16/20\n",
            " 645/1563 [===========>..................] - ETA: 26s - loss: 1.0344 - acc: 0.6384\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.0424 - acc: 0.6355 - val_loss: 0.9474 - val_acc: 0.6782\n",
            "Epoch 17/20\n",
            " 663/1563 [===========>..................] - ETA: 25s - loss: 1.0304 - acc: 0.6424"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.0324 - acc: 0.6407 - val_loss: 0.9347 - val_acc: 0.6794\n",
            "Epoch 18/20\n",
            " 615/1563 [==========>...................] - ETA: 27s - loss: 1.0288 - acc: 0.6397"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.0327 - acc: 0.6401 - val_loss: 0.9247 - val_acc: 0.6875\n",
            "Epoch 19/20\n",
            " 639/1563 [===========>..................] - ETA: 26s - loss: 1.0306 - acc: 0.6431"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.0296 - acc: 0.6439 - val_loss: 0.9020 - val_acc: 0.6918\n",
            "Epoch 20/20\n",
            " 619/1563 [==========>...................] - ETA: 27s - loss: 1.0237 - acc: 0.6454"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 46s 30ms/step - loss: 1.0215 - acc: 0.6452 - val_loss: 0.9484 - val_acc: 0.6764\n",
            "Saved trained model at /content/saved_models/keras_cifar10_trained_model.h5 \n",
            "10000/10000 [==============================] - 2s 181us/step\n",
            "Test loss: 0.8056231224060059\n",
            "Test accuracy: 0.7182\n",
            "10000/10000 [==============================] - 2s 161us/step\n",
            "Test loss2: 0.9484411451339722\n",
            "Test accuracy2: 0.6764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kdJxttjNcqZk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataAugmentation_eg2_效能验证.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/jsxyhelu/DateSets/blob/master/DataAugmentation_eg2_%E6%95%88%E8%83%BD%E9%AA%8C%E8%AF%81.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ABxMy4ObEXUW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "8c0f7369-4e03-4ee8-a47b-c59f43e3c196"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.layers.core import Dense, Flatten, Activation, Dropout\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.utils import generic_utils\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "\n",
        "def preprocess_data(x):\n",
        "    x /= 255\n",
        "    x -= 0.5\n",
        "    x *= 2\n",
        "    return x\n",
        "\n",
        "# 预处理\n",
        "x_train = x_train.astype(np.float32)\n",
        "x_test = x_test.astype(np.float32)\n",
        "\n",
        "x_train = preprocess_data(x_train)\n",
        "x_test = preprocess_data(x_test)\n",
        "\n",
        "# one-hot encoding\n",
        "n_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "\n",
        "# 取 20% 的训练数据\n",
        "x_train_part = x_train[:10000]\n",
        "y_train_part = y_train[:10000]\n",
        "\n",
        "print(x_train_part.shape, y_train_part.shape)\n",
        "\n",
        "# 建立一个简单的卷积神经网络,序贯结构\n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(64, (3,3), input_shape=(32,32,3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(scale=False, center=False))\n",
        "\n",
        "    model.add(Conv2D(32, (3,3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization(scale=False, center=False))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(n_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# 训练参数\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "#epochs = 2\n",
        "#cifar-10 20%数据,训练结果\n",
        "model = build_model()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train_part, y_train_part, epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.1)\n",
        "\n",
        "loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('Loss: ', loss)\n",
        "print('Accuracy: ', acc)\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n",
            "(10000, 32, 32, 3) (10000, 10)\n",
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/20\n",
            "9000/9000 [==============================] - 7s 825us/step - loss: 1.7662 - acc: 0.4022 - val_loss: 1.3376 - val_acc: 0.5190\n",
            "Epoch 2/20\n",
            "9000/9000 [==============================] - 6s 679us/step - loss: 1.2491 - acc: 0.5601 - val_loss: 1.1931 - val_acc: 0.5840\n",
            "Epoch 3/20\n",
            "7872/9000 [=========================>....] - ETA: 0s - loss: 0.9622 - acc: 0.6585"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9000/9000 [==============================] - 6s 681us/step - loss: 0.9636 - acc: 0.6601 - val_loss: 1.1518 - val_acc: 0.5800\n",
            "Epoch 4/20\n",
            "9000/9000 [==============================] - 6s 681us/step - loss: 0.7655 - acc: 0.7346 - val_loss: 1.1195 - val_acc: 0.6120\n",
            "Epoch 5/20\n",
            "9000/9000 [==============================] - 6s 674us/step - loss: 0.6081 - acc: 0.7910 - val_loss: 1.1606 - val_acc: 0.6010\n",
            "Epoch 6/20\n",
            "8672/9000 [===========================>..] - ETA: 0s - loss: 0.5062 - acc: 0.8278"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9000/9000 [==============================] - 6s 667us/step - loss: 0.5084 - acc: 0.8270 - val_loss: 1.1882 - val_acc: 0.6240\n",
            "Epoch 7/20\n",
            "9000/9000 [==============================] - 6s 668us/step - loss: 0.4107 - acc: 0.8633 - val_loss: 1.2267 - val_acc: 0.6090\n",
            "Epoch 8/20\n",
            "9000/9000 [==============================] - 6s 673us/step - loss: 0.3220 - acc: 0.8992 - val_loss: 1.2761 - val_acc: 0.6160\n",
            "Epoch 9/20\n",
            "8704/9000 [============================>.] - ETA: 0s - loss: 0.2667 - acc: 0.9125"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9000/9000 [==============================] - 6s 677us/step - loss: 0.2685 - acc: 0.9116 - val_loss: 1.3205 - val_acc: 0.6100\n",
            "Epoch 10/20\n",
            "9000/9000 [==============================] - 6s 663us/step - loss: 0.2516 - acc: 0.9180 - val_loss: 1.3014 - val_acc: 0.6220\n",
            "Epoch 11/20\n",
            "9000/9000 [==============================] - 6s 675us/step - loss: 0.1998 - acc: 0.9368 - val_loss: 1.4843 - val_acc: 0.5900\n",
            "Epoch 12/20\n",
            "8672/9000 [===========================>..] - ETA: 0s - loss: 0.2033 - acc: 0.9343"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9000/9000 [==============================] - 6s 677us/step - loss: 0.2054 - acc: 0.9340 - val_loss: 1.4964 - val_acc: 0.6070\n",
            "Epoch 13/20\n",
            "9000/9000 [==============================] - 6s 666us/step - loss: 0.1795 - acc: 0.9438 - val_loss: 1.4162 - val_acc: 0.6210\n",
            "Epoch 14/20\n",
            "9000/9000 [==============================] - 6s 673us/step - loss: 0.2183 - acc: 0.9246 - val_loss: 1.4455 - val_acc: 0.6250\n",
            "Epoch 15/20\n",
            "8672/9000 [===========================>..] - ETA: 0s - loss: 0.1519 - acc: 0.9510"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9000/9000 [==============================] - 6s 676us/step - loss: 0.1514 - acc: 0.9511 - val_loss: 1.3598 - val_acc: 0.6460\n",
            "Epoch 16/20\n",
            "9000/9000 [==============================] - 6s 670us/step - loss: 0.1348 - acc: 0.9561 - val_loss: 1.4730 - val_acc: 0.6150\n",
            "Epoch 17/20\n",
            "9000/9000 [==============================] - 6s 672us/step - loss: 0.1258 - acc: 0.9593 - val_loss: 1.5136 - val_acc: 0.6050\n",
            "Epoch 18/20\n",
            "8576/9000 [===========================>..] - ETA: 0s - loss: 0.1111 - acc: 0.9657"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9000/9000 [==============================] - 6s 669us/step - loss: 0.1126 - acc: 0.9651 - val_loss: 1.5105 - val_acc: 0.6250\n",
            "Epoch 19/20\n",
            "9000/9000 [==============================] - 6s 676us/step - loss: 0.1276 - acc: 0.9559 - val_loss: 1.4222 - val_acc: 0.6350\n",
            "Epoch 20/20\n",
            "9000/9000 [==============================] - 6s 669us/step - loss: 0.1223 - acc: 0.9589 - val_loss: 1.4725 - val_acc: 0.6250\n",
            "10000/10000 [==============================] - 2s 204us/step\n",
            "Loss:  1.5472557198524475\n",
            "Accuracy:  0.6228\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v4DZMrYJKp3L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "采用文档中提示所谓自动方法"
      ]
    },
    {
      "metadata": {
        "id": "Qrsp4o6YKoPm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "355f5939-b66c-444d-cb1a-107546c2992c"
      },
      "cell_type": "code",
      "source": [
        "img_generator.fit(x_train_part)\n",
        "\n",
        "# fits the model_2 on batches with real-time data augmentation:\n",
        "model_2.fit_generator(img_generator.flow(x_train_part, y_train_part, batch_size=batch_size),\n",
        "                    steps_per_epoch=len(x_train_part), epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            " 3676/10000 [==========>...................] - ETA: 3:08 - loss: 1.5007 - acc: 0.4640"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 7318/10000 [====================>.........] - ETA: 1:19 - loss: 1.3568 - acc: 0.5147"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 9980/10000 [============================>.] - ETA: 0s - loss: 1.2916 - acc: 0.5389"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 296s 30ms/step - loss: 1.2912 - acc: 0.5390\n",
            "Epoch 2/20\n",
            " 1061/10000 [==>...........................] - ETA: 4:29 - loss: 1.0764 - acc: 0.6163"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 3961/10000 [==========>...................] - ETA: 3:02 - loss: 1.0493 - acc: 0.6271"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 7081/10000 [====================>.........] - ETA: 1:27 - loss: 1.0238 - acc: 0.6364"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 9528/10000 [===========================>..] - ETA: 13s - loss: 1.0081 - acc: 0.6429"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 296s 30ms/step - loss: 1.0053 - acc: 0.6440\n",
            "Epoch 3/20\n",
            "  867/10000 [=>............................] - ETA: 4:27 - loss: 0.9438 - acc: 0.6691"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 3301/10000 [========>.....................] - ETA: 3:16 - loss: 0.9335 - acc: 0.6713"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 5654/10000 [===============>..............] - ETA: 2:09 - loss: 0.9239 - acc: 0.6743"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 8797/10000 [=========================>....] - ETA: 35s - loss: 0.9126 - acc: 0.6782"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 299s 30ms/step - loss: 0.9076 - acc: 0.6794\n",
            "Epoch 4/20\n",
            "  270/10000 [..............................] - ETA: 4:45 - loss: 0.8659 - acc: 0.6964"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}